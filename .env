# use localhost if running natively on macbook with python else use host.containers.internal when using podman container for all host.

# OLLAMA_HOST=http://0.0.0.0:11434
OLLAMA_HOST=http://host.containers.internal:11434
EMBEDDING_MODEL=intfloat/multilingual-e5-large-instruct
OLLAMA_MODEL=llama3.1:8b

# MLflow Configuration
MLFLOW_TRACKING_URI=http://host.containers.internal:5001
MLFLOW_EXPERIMENT_NAME=plant_disease_classification
MLFLOW_ARTIFACT_LOCATION=./mlflow_artifacts
MLFLOW_REGISTRY_URI=http://host.containers.internal:5001

# Other Configuration
DEBUG=false

LOG_LEVEL=debug


# CHROMA_HOST=0.0.0.0
CHROMA_HOST=host.containers.internal
CHROMA_PORT=8000

# API_HOST=0.0.0.0
# API_HOST=host.containers.internal
API_PORT=8081
API_RELOAD=false
LOG_LEVEL=INFO

